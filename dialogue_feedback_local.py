import os
import tempfile
import uuid
import numpy as np
import librosa
import soundfile as sf
import json
import logging
import traceback
from pydub import AudioSegment
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

# NLP/LLM (ì˜µì…˜)
from transformers import pipeline
import spacy

# WhisperëŠ” ì§€ì—°ë¡œë”©(ì‚¬ìš©ì‹œ ë¡œë“œ)
try:
    import whisper as _whisper_module
except Exception:
    _whisper_module = None

# === ë¡œê¹… ì„¤ì • ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dialogue_feedback_local")

# === ì„¤ì • ===
LANG = "ko"  # ì „ì‚¬ ì–¸ì–´ ì„¤ì •
WHISPER_MODEL_NAME = os.getenv("WHISPER_MODEL", "base")

# spaCy ë¡œë“œ
try:
    nlp = spacy.load("ko_core_news_sm")
    logger.info("spaCy ko_core_news_sm loaded")
except Exception:
    try:
        nlp = spacy.load("en_core_web_sm")
        logger.info("spaCy en_core_web_sm loaded")
    except Exception:
        nlp = None
        logger.info("spaCy model not loaded; NLP features limited")

# Whisper ëª¨ë¸ í•¸ë“¤ (ì§€ì—°ë¡œë”©)
whisper_model = None

def ensure_whisper_model():
    global whisper_model
    if whisper_model is not None:
        return whisper_model
    if _whisper_module is None:
        logger.error("whisper íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    try:
        logger.info(f"Loading whisper model '{WHISPER_MODEL_NAME}' ...")
        whisper_model = _whisper_module.load_model(WHISPER_MODEL_NAME)
        logger.info("whisper model loaded")
        return whisper_model
    except Exception as e:
        logger.error(f"whisper model load failed: {str(e)}")
        whisper_model = None
        return None

app = FastAPI(title="Dialogue Correction AI - Local Whisper Prototype")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------- [1] ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •ë¨) ----------------------
def save_upload_to_wav(upload_file: UploadFile, target_rate=16000):
    tmp_in = None
    tmp_out = None
    try:
        suffix = os.path.splitext(upload_file.filename)[1].lower() or ".tmp"
        tmp_in = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        content = upload_file.file.read()
        tmp_in.write(content)
        tmp_in.flush()
        
        tmp_out = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        
        # pydubë¥¼ ì‚¬ìš©í•´ ë³€í™˜
        audio = AudioSegment.from_file(tmp_in.name)
        audio = audio.set_frame_rate(target_rate).set_channels(1)
        audio.export(tmp_out.name, format="wav")
        
        logger.info(f"Saved uploaded audio to {tmp_out.name}")
        return tmp_out.name
    except Exception as e:
        logger.error(f"save_upload_to_wav error: {str(e)}")
        # íŒŒì¼ ì •ë¦¬ (ì•ˆì „í•œ ë¬¸ë²•ìœ¼ë¡œ ë³€ê²½)
        if tmp_in:
            try:
                os.unlink(tmp_in.name)
            except Exception:
                pass
        if tmp_out:
            try:
                os.unlink(tmp_out.name)
            except Exception:
                pass
        raise
    finally:
        if tmp_in:
            try:
                tmp_in.close()
            except Exception:
                pass

def load_audio(path, sr=16000):
    y, sr = librosa.load(path, sr=sr, mono=True)
    return y, sr

# ---------------------- [2] Whisper ì „ì‚¬ ----------------------
def transcribe(wav_path):
    model = ensure_whisper_model()
    if model is None:
        return ""
    try:
        result = model.transcribe(wav_path, language=LANG)
        text = result.get("text", "").strip()
        return text
    except Exception as e:
        logger.error(f"Whisper transcription failed: {str(e)}")
        return ""

# ---------------------- [3] Prosody (ìŒì„± ë¶„ì„) ----------------------
def analyze_prosody(y, sr):
    metrics = {}
    try:
        duration = len(y) / sr
        metrics['duration_sec'] = duration

        # RMS (ìŒëŸ‰)
        rms = librosa.feature.rms(y=y)[0]
        metrics['rms_mean'] = float(np.mean(rms))
        metrics['rms_std'] = float(np.std(rms))

        # Tempo (ì†ë„)
        onset_env = librosa.onset.onset_strength(y=y, sr=sr)
        try:
            if hasattr(librosa.feature, 'rhythm'):
                tempo = librosa.feature.rhythm.tempo(onset_envelope=onset_env, sr=sr)
            else:
                tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)
            metrics['tempo_bpm'] = float(tempo[0])
        except Exception:
            metrics['tempo_bpm'] = None

        # Pitch (ì–µì–‘)
        try:
            f0 = librosa.yin(y, fmin=60, fmax=500, sr=sr)
            f0_clean = f0[~np.isnan(f0)]
            metrics['f0_std_hz'] = float(np.std(f0_clean)) if len(f0_clean) > 0 else 0.0
            metrics['f0_mean_hz'] = float(np.mean(f0_clean)) if len(f0_clean) > 0 else 0.0
        except Exception:
            metrics['f0_std_hz'] = 0.0
            metrics['f0_mean_hz'] = 0.0

        # ì¹¨ë¬µ/ë°œí™” êµ¬ê°„
        intervals = librosa.effects.split(y, top_db=30)
        speech_durations = [(end - start) / sr for start, end in intervals]
        metrics['speech_total_sec'] = sum(speech_durations)
        metrics['silence_total_sec'] = duration - metrics['speech_total_sec']
        
    except Exception as e:
        logger.error(f"analyze_prosody error: {str(e)}")
    return metrics

# ---------------------- [4] NLP ë¶„ì„ (CNN ì˜¤ë¥˜ ë°©ì§€ ì ìš©) ----------------------
def analyze_nlp(text):
    out = {}
    
    # í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¶„ì„ ì¤‘ë‹¨ (CNN ì˜¤ë¥˜ ë°©ì§€)
    if not text or len(text.strip()) < 2:
        return {
            "raw_text": "",
            "summary": "ëŒ€í™” ë‚´ìš©ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ëª©ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ ì¡ìŒì´ ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)",
            "word_count": 0,
            "sentence_count": 0,
            "pos_counts": {}
        }

    try:
        out['raw_text'] = text
        words = text.split()
        out['word_count'] = len(words)
        out['char_count'] = len(text)

        if nlp:
            doc = nlp(text)
            out['sentence_count'] = len(list(doc.sents))
            pos_counts = {}
            for tok in doc:
                pos_counts[tok.pos_] = pos_counts.get(tok.pos_, 0) + 1
            out['pos_counts'] = pos_counts
        else:
            out['sentence_count'] = 0
            out['pos_counts'] = {}

        # ìš”ì•½ (í…ìŠ¤íŠ¸ê°€ 50ì ì´ìƒì¼ ë•Œë§Œ ìˆ˜í–‰)
        if len(text) > 50:
            try:
                summarizer = pipeline('summarization', model="sshleifer/distilbart-cnn-12-6")
                input_len = len(words)
                max_len = max(20, int(input_len * 0.6))
                summary_result = summarizer(text, max_length=max_len, min_length=10)
                out['summary'] = summary_result[0]['summary_text']
            except Exception as e:
                logger.warning(f"Summarization failed: {e}")
                out['summary'] = "ìš”ì•½ ì‹¤íŒ¨"
        else:
            out['summary'] = text 

    except Exception as e:
        logger.error(f"analyze_nlp error: {str(e)}")
        out['raw_text'] = text
        out['summary'] = "ë¶„ì„ ì¤‘ ì˜¤ë¥˜"
    
    return out

# ---------------------- [5] ì ìˆ˜ ê³„ì‚° ----------------------
def evaluate_all(prosody_metrics, nlp_metrics):
    scores = {}
    try:
        # 1. ì†ë„ ì ìˆ˜
        tempo = prosody_metrics.get('tempo_bpm', 0)
        if not tempo:
            scores['speed'] = 50
        else:
            if 80 <= tempo <= 160:
                scores['speed'] = 90
            else:
                diff = min(abs(tempo - 80), abs(tempo - 160))
                scores['speed'] = max(40, 90 - diff * 0.5)

        # 2. ëª…í™•ì„±
        rms_std = prosody_metrics.get('rms_std', 0)
        scores['clarity'] = min(100, max(50, rms_std * 500))

        # 3. ì–µì–‘
        f0_std = prosody_metrics.get('f0_std_hz', 0)
        scores['intonation'] = min(100, max(40, f0_std * 2))

        # 4. êµ¬ì¡°
        sent_count = nlp_metrics.get('sentence_count', 0)
        if sent_count > 0:
            scores['structure'] = 80 
        else:
            scores['structure'] = 40

        # 5. ì²­ì¤‘ ì¹œí™”ì„±
        scores['audience_friendliness'] = (scores['clarity'] + scores['intonation']) / 2

        # ì¢…í•© ì ìˆ˜
        total = (
            scores['speed'] * 0.2 + 
            scores['clarity'] * 0.2 + 
            scores['intonation'] * 0.2 + 
            scores['structure'] * 0.2 + 
            scores['audience_friendliness'] * 0.2
        )
        scores['overall'] = round(total, 1)

        # ì†Œìˆ˜ì  ì •ë¦¬
        for k, v in scores.items():
            scores[k] = round(v, 1)

    except Exception as e:
        logger.error(f"evaluate_all error: {str(e)}")
        scores = {'overall': 0}
    return scores

# ---------------------- [6] ì‚¬ìš©ì í”¼ë“œë°± ìƒì„± (í™”ë©´ ì—°ê²°ìš©) ----------------------
def generate_friendly_feedback(prosody, nlp, scores):
    """
    LLM ì—†ì´ ë¡œì§ ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•œ í”¼ë“œë°± ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨ ì‹œ
    if not nlp.get('raw_text'):
        return "âš ï¸ ìŒì„±ì´ ëª…í™•í•˜ê²Œ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆì´í¬ë¥¼ ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ëŒ€ê³  ë§ì”€í•´ ì£¼ì„¸ìš”."

    total = scores.get('overall', 0)
    
    # ì ìˆ˜ëŒ€ë³„ ë©˜íŠ¸
    if total >= 80:
        base_comment = "ğŸ‘ ì™€ìš°! ì „ë‹¬ë ¥ì´ ë§¤ìš° ë›°ì–´ë‚œ ìŠ¤í”¼ì¹˜ì…ë‹ˆë‹¤."
    elif total >= 60:
        base_comment = "ğŸ‘ ì¢‹ì€ í¸ì´ì—ìš”! ì¡°ê¸ˆë§Œ ë” ìì‹ ê° ìˆê²Œ ë§í•´ë³´ì„¸ìš”."
    else:
        base_comment = "ğŸ’ª ëª©ì†Œë¦¬ í†¤ì´ë‚˜ ì†ë„ë¥¼ ì¡°ì ˆí•´ì„œ ì „ë‹¬ë ¥ì„ ë†’ì—¬ë³´ì„¸ìš”."

    # ì„¸ë¶€ ì¡°ì–¸ ì¶”ê°€
    advice = []
    tempo = prosody.get('tempo_bpm', 0)
    if tempo and (tempo > 160):
        advice.append("ë§ì´ ì¡°ê¸ˆ ë¹ ë¦…ë‹ˆë‹¤. ì²œì²œíˆ ë§í•´ë³´ì„¸ìš”.")
    elif tempo and (tempo < 80):
        advice.append("ë§ì´ ì¡°ê¸ˆ ëŠë¦½ë‹ˆë‹¤. ë¦¬ë“¬ê°ì„ ì‚´ë ¤ë³´ì„¸ìš”.")

    if prosody.get('f0_std_hz', 0) < 10:
        advice.append("ëª©ì†Œë¦¬ í†¤ì´ ë‹¤ì†Œ ë‹¨ì¡°ë¡­ìŠµë‹ˆë‹¤. ì–µì–‘ì„ ë„£ì–´ë³´ì„¸ìš”.")

    if advice:
        return f"{base_comment} ({' '.join(advice)})"
    else:
        return base_comment

# ---------------------- [API] ì—”ë“œí¬ì¸íŠ¸ ----------------------
@app.post('/upload_audio')
async def upload_audio(file: UploadFile = File(...), role: str = 'ì¼ë°˜ëŒ€í™”'):
    tmp_wav = None
    try:
        tmp_wav = save_upload_to_wav(file)
        y, sr = load_audio(tmp_wav)
        
        transcript = transcribe(tmp_wav)
        prosody = analyze_prosody(y, sr)
        nlp_metrics = analyze_nlp(transcript)
        scores = evaluate_all(prosody, nlp_metrics)
        
        # [ìˆ˜ì •] í”„ë¡ íŠ¸ì—”ë“œê°€ 'feedback' í•„ë“œë¥¼ í™”ë©´ì— ë¿Œë ¤ì¤€ë‹¤ê³  ê°€ì •í•˜ê³ 
        # ì—¬ê¸°ì— ì¹œì ˆí•œ ë©˜íŠ¸ë¥¼ ë„£ìŠµë‹ˆë‹¤.
        friendly_comment = generate_friendly_feedback(prosody, nlp_metrics, scores)

        # [ì¤‘ìš”] í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ í‚¤ ì´ë¦„(transcript, prosody ë“±)ì„ ì›ë˜ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        result = {
            "transcript": transcript,
            "prosody": prosody,
            "nlp": nlp_metrics,
            "scores": scores,
            "feedback": friendly_comment  # LLM ê²½ê³  ë©”ì‹œì§€ ëŒ€ì‹  ìœ ìš©í•œ í”¼ë“œë°± ì „ë‹¬
        }

        return JSONResponse(result)
        
    except Exception as e:
        logger.error(f"upload_audio handler error: {str(e)}")
        logger.error(traceback.format_exc())
        return JSONResponse({"error": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ", "detail": str(e)}, status_code=500)
    finally:
        if tmp_wav and os.path.exists(tmp_wav):
            try: os.unlink(tmp_wav)
            except: pass

@app.get('/health')
async def health():
    return {"status": "ok"}